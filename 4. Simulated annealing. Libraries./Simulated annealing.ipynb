{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Simulated annealing. Libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider cooling of metal which consists of freely moving atoms searching for position with minimal energy. Due to high temperature, they have quite big kinetic energy and can end up in totally different positions with different potential energies. However, as temperature decreases, kinetic energy decreases and atoms move to positions with higher potential energy with less probablity, which means that on average atoms are moving towards minimum. Since atoms had time to \"explore\" their surroundings they are very likely ending in position with minimal or close to minimal energy. <br>\n",
    "Research of this physical phenomena in 80s resulted in computer modeling of this process that became base for simulated annealing algorithm. Now let's consider algorithm's pseudocode in Python, where we try to find **state** with minimal **energy**:\n",
    "```python\n",
    "s=s0 #initial state\n",
    "for i in range(number_of_iterations):\n",
    "    T=temperature(i)\n",
    "    s_new=neighbour(s)\n",
    "    if probability_of_transition(Energy(s),Energy(s_new),T)>random(0,1):\n",
    "        s=s_new\n",
    "        \n",
    "print(s)\n",
    "```\n",
    "We can see 5 important facts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is key for solution which is defined explicitly only by problem we are trying to solve. Basically, it has input - state, which can be one number or number list and output - one number (energy) we are optimizing for. For example, in travelling salesman problem energy function is distance function whose input is sequence of cities' numbers - path. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to do a lot of iterations which will on average get state closer and closer to optimal. Overall, the more iterations you do the larger probability of getting needed solution. However, computing time always has to be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generation of a neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get better results, initial state has to move in coordinate space. This movement is achieved through generation random neighbour by slightly tweaking parametres of current state. For example, new path in travelling salesman problem can be generated by swapping two cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability of transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main idea behind effectiveness of simulated annealing algorithm is exploring coordinate space before making final decisions. In contrary, greedy algorithm will often fail in finding of global minimum because it always picks better state as it seems *right now*. However, we have to discourage (but not fully shutdown) picking worse states by introducing probability of picking worse state which is, obviously, less than 1. This probability has to get lower and lower as initial exploration is finished, which is achieved with help of temperature function. Now we can write how function probability_of_transition(Energy(s),Energy(s_new),T):\n",
    "```python\n",
    "def probability_of_transition(Energy_s,Energy_s_new,T):\n",
    "    if (Energy_s_new<Energy_s):\n",
    "        p=1 #we are moving to better state with 100% probability\n",
    "    else:\n",
    "        Delta_E=Energy_s_new-Energy_s #probability of transition depends on how \"bad\" is new state\n",
    "        p=math.exp(-Delta_E/(Delta_E_Avg*T)) #this probability will be always less than 1\n",
    "        \n",
    "    return p\n",
    "```\n",
    "The most mysterious string of code is probably definition of probability in second case: $$p=e^{-\\frac{\\Delta E}{\\Delta E_{avg}T}}$$ First of all, we calculate difference in energies between states, because, from physical point of view there is smaller probability that atom gets enough kinetic energy to transit to neigbour state. And from optimization point we cannot allow getting in not beneficial states very often because state can waste a lot of time returning back. Secondly, we have new value $\\Delta E_{avg}$ which serves as standard value for coherence between early and late parts of optimization. Thirdly, we have temperature value which controls probability of picking with time. You can easily see that with lowering temperature, whole probability gets smaller. The same behaviour occurs in real world where with lowering temperature probability of getting high kinetic energy quickly reduces. Finally, exponent is took from Physics laws. Since numbers $\\Delta E$,$\\Delta E_{avg}$ and $T$ are positive, exponent is always between 0 and 1 plus behaviour of this function make it perfect candidate for probability calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From physical analogy we introduce temperature or ability to freely move to positions with higher energy. This function is usually fully derived from 3 numbers: initial probability $p_0$ of transition with $\\Delta E=\\Delta E_{avg}$, final probability $p_n$ of transition with $\\Delta E=\\Delta E_{avg}$ and number of iterations $n$. From definition of transition probability initial and final temperatures are equal to $T_0=-1/\\ln(p_0)$ and $T_n=-1/\\ln(p_n)$, respectively. Then we introduce the rate of decay $f=\\sqrt[n]{\\frac{T_n}{T_0}}$, which helps simply recursively calculate temperature for current iteration as $T_i=fT_{i-1}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math #information about math library is in the second notebook\n",
    "\n",
    "n=10\n",
    "pn=0.001    #defining 3 parametres\n",
    "p0=0.5\n",
    "\n",
    "T0=-1/math.log(p0) #math.log(x) is natural logarithm ln(x)\n",
    "Tn=-1/math.log(pn)\n",
    "f=(Tn/T0)**(1/n)   \n",
    "\n",
    "print('Initial temperature:',T0)\n",
    "print('Final temperature:',Tn)\n",
    "print('Rate of decay:',f)\n",
    "\n",
    "T=T0 #start of cycle\n",
    "for i in range(n):\n",
    "    T=T*f\n",
    "    print('Iteration',str(i+1),' Temperature:',str(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application in traveling salesman problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we rewrite helping functions from previous lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_map(n,seed):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "    random.seed(seed) #seed of random number generator, it allows to get the same map everytime\n",
    "\n",
    "    #n is a number of cities\n",
    "    x=[] #list of x coordinates of cities (in km)\n",
    "    y=[] #list of y coordinates of cities (in km)\n",
    "    names=[] #list of cities' names\n",
    "\n",
    "    #now we create loop to append coordinates to lists\n",
    "    for i in range(n):\n",
    "        x.append(random.randint(0,1000))\n",
    "        y.append(random.randint(0,1000))\n",
    "        names.append(chr(65+i)) #we name cities as A,B,C...\n",
    "\n",
    "\n",
    "    #finally, we plot map\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.scatter(x,y)\n",
    "    for i in range(n): plt.text(x[i]+10,y[i]-20,names[i]) #adding names of cities\n",
    "    plt.show()\n",
    "    return x,y,names #returns coordinates of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_dictionary(x,y):  \n",
    "    n=len(x) #number of cities\n",
    "    cities={} #dictionary which stores all possible distances between two cities\n",
    "    for i in range(n):\n",
    "        city={} #we create small dictionary which includes distances from city i to all other cities\n",
    "        for k in range(n):\n",
    "            if (i!=k): \n",
    "                city[k]=((x[i]-x[k])**2+(y[i]-y[k])**2)**(1/2) #calculating distance\n",
    "\n",
    "        cities[i]=city\n",
    "\n",
    "    return cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=45 #number of cities\n",
    "x,y,names=create_map(m,78)\n",
    "cities=distance_dictionary(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create random path - randomly shuffled list of numbers from 0 to n-1 plus first element (because path is closed by definition) and defining function distance, which, basically, is energy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "s=list(range(m)) #creating path 0-1-2-...\n",
    "random.shuffle(s) #shuffling it\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance(path,cities):\n",
    "    d=0\n",
    "    for i in range(len(path)-1): d+=cities[path[i]][path[i+1]]\n",
    "    d+=cities[path[len(path)-1]][path[0]]\n",
    "    return d        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining parametres\n",
    "n=1000000\n",
    "pn=1E-6  \n",
    "p0=0.5\n",
    "\n",
    "T0=-1/math.log(p0)\n",
    "Tn=-1/math.log(pn)\n",
    "f=(Tn/T0)**(1/n)   \n",
    "\n",
    "T=T0 \n",
    "for i in range(n):\n",
    "    if (T<Tn): break\n",
    "    T=T*f    \n",
    "    l = random.randint(2, m-1)\n",
    "    k = random.randint(0, m-l)\n",
    "    s_new=s[:]\n",
    "    s_new[k:(k+l)] = reversed(s_new[k:(k+l)]) #swapping part of s to get s_new\n",
    "    \n",
    "    d=distance(s,cities)\n",
    "    d_new=distance(s_new,cities)\n",
    "    delta_d=math.fabs(d_new-d) #we always calculate delta_d for calculating delta_d_avg\n",
    "    if (i==0): \n",
    "        delta_d_avg=delta_d #assign delta_d_avg when its equal 0\n",
    "    else:\n",
    "        delta_d_avg=(i*delta_d_avg+delta_d)/(i+1) #changing delta_d_avg  \n",
    "    #probability_of_transition function    \n",
    "    if (d_new<=d):\n",
    "        p=1\n",
    "    else: \n",
    "        p=math.exp(-delta_d/(delta_d_avg*T))\n",
    "    if (p>=random.random()): s=s_new[:]\n",
    "        \n",
    "    if (i%(n//10)==0): print(d) #print distance 10 times during cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot found path on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#After we have found optimal or close to optimal path, we can show it on map\n",
    "def path_on_map(route,x,y,names,cities):\n",
    "    import matplotlib.pyplot as plt\n",
    "    n=len(names) #number of cities\n",
    "    optimal_x=[] #consecutive coordinates of cities from the best route\n",
    "    optimal_y=[]\n",
    "    for i in range(n): \n",
    "        optimal_x.append(x[s[i]])\n",
    "        optimal_y.append(y[s[i]])\n",
    "\n",
    "    optimal_x.append(optimal_x[0])    \n",
    "    optimal_y.append(optimal_y[0])  \n",
    "\n",
    "    plt.figure(figsize=(7,7))    \n",
    "    plt.plot(optimal_x,optimal_y,'r')\n",
    "    plt.scatter(x,y)\n",
    "    for i in range(n): plt.text(x[i]+10,y[i]-20,names[i]) #adding names of cities\n",
    "    plt.title(\"Distance: \"+str(int(distance(s,cities)))+\" km\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_on_map(s,x,y,names,cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the path is pretty close to optimal. If you want better result, you should play with 3 parametres we defined. And that is probalby the major problem with simulated annealing - you have to specially tune these numbers (which later will be called *hyperparametres*) for each problem you are solving. However, the result is much better than in case of greedy algorithm. Moreover, simulated annealing has one more huge advantage over greedy algorithm - it can work with continuous functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application in optimization of continuous functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's optimize function $f(x)$ of 2 real variables: $$f(x)=\\frac{1}{5}+x^2+y^2-\\frac{1}{10}\\cos(6\\pi x)-\\frac{1}{10}\\cos(6\\pi y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x,y):\n",
    "    return 0.2 + x**2 + y**2 - 0.1*np.cos(6.0*3.1415*x) - 0.1*np.cos(6.0*3.1415*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we import several libraries for much easier work and representation of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np #library for work with numeric lists - we are going to learn about it in several lessons\n",
    "import matplotlib.pyplot as plt #builder of graphs\n",
    "import matplotlib.animation as an #creator of animations\n",
    "from IPython.display import HTML #HTML player of animations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we can plot color graph of function (blue means smaller values and yellow - larger ones)\n",
    "a=1\n",
    "na=200\n",
    "x=np.linspace(-a,a,na)\n",
    "y=np.linspace(-a,a,na).reshape(-1, 1)\n",
    "fig=plt.figure(figsize=(7,7))\n",
    "ax=plt.subplot(111)\n",
    "im = ax.imshow(f(x,y),cmap='viridis',animated=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this graph naturally has a lot of minimums and maximums. This is the perfect test of searching one global minimum for simulated annealing. Next we are defining hyperparametres of algorithm and run it. Algorithm hasn't changed much except energy function which is now, obviously, equal to $f(x)$. In parallel, we are writing down values (x,y) or current state for later creating animation of searching for minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Source: http://apmonitor.com/me575/index.php/Main/SimulatedAnnealing\n",
    "#Size of boundaries\n",
    "a=1\n",
    "# Number of cycles\n",
    "n = 2500\n",
    "# Number of accepted solutions\n",
    "na = 0.0\n",
    "# Probability of accepting worse solution at the start\n",
    "p1 = 0.7\n",
    "# Probability of accepting worse solution at the end\n",
    "pn = 0.001\n",
    "# Initial temperature\n",
    "t1 = -1.0/np.log(p1)\n",
    "# Final temperature\n",
    "tn = -1.0/np.log(pn)\n",
    "# Fractional reduction every cycle\n",
    "frac = (tn/t1)**(1.0/(n-1.0))\n",
    "# Initialize x and y - history of points\n",
    "x=np.zeros(n+1)\n",
    "y=np.zeros(n+1)\n",
    "x[0]=0.7\n",
    "y[0]=0.8\n",
    "#The best value of the function\n",
    "fc=f(x[0],y[0])\n",
    "# DeltaE Average\n",
    "DeltaE_avg = 0.0\n",
    "#Main point and experimental point\n",
    "xi=x[0]\n",
    "yi=y[0]\n",
    "xc=x[0]\n",
    "yc=y[0]\n",
    "print(xi,yi,frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=t1 #Initial temperature\n",
    "for i in range(n):     \n",
    "    # Generate new point\n",
    "    xi=xc+a*(np.random.rand() - 0.5)\n",
    "    yi=yc+a*(np.random.rand() - 0.5)    \n",
    "    # Clip to upper and lower bounds \n",
    "    #There is a chance that point can randomly get out of boundaries \n",
    "    #In that case we return point on the edge of boundaries using following code\n",
    "    xi = max(min(xi,a),-a)\n",
    "    yi = max(min(yi,a),-a)   \n",
    "    DeltaE = abs(f(xi,yi)-fc)\n",
    "    if (f(xi,yi)>fc):\n",
    "        # Initialize DeltaE_avg if a worse solution was found\n",
    "        # on the first iteration\n",
    "        if (i==0): DeltaE_avg = DeltaE\n",
    "        # objective function is worse\n",
    "        # generate probability of acceptance\n",
    "        p = np.exp(-DeltaE/(DeltaE_avg * t))        \n",
    "        # determine whether to accept worse point\n",
    "        if (np.random.rand()<p):\n",
    "            # accept the worse solution\n",
    "            accept = True\n",
    "        else:\n",
    "            # don't accept the worse solution\n",
    "            accept = False\n",
    "    else:\n",
    "        # objective function is lower, automatically accept\n",
    "        accept = True\n",
    "    if (accept==True): \n",
    "        #update value of function\n",
    "        xc=xi\n",
    "        yc=yi\n",
    "        fc = f(xi,yi)        \n",
    "        # increment number of accepted solutions\n",
    "        na = na + 1.0\n",
    "        # update DeltaE_avg\n",
    "        DeltaE_avg = (DeltaE_avg * (na-1.0) +  DeltaE) / na\n",
    "    # Record the best x and y values at the end of every cycle    \n",
    "    x[i+1] = xc\n",
    "    y[i+1] = yc   \n",
    "    # Lower the temperature for next cycle\n",
    "    t = frac * t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define one more function for creating animation and draw it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updatefig(*args):\n",
    "    global i\n",
    "    i+=1\n",
    "    ind=i*24\n",
    "    xx=na*(1+x[ind]/a)/2\n",
    "    yy=na*(1+y[ind]/a)/2\n",
    "    line.set_data([xx],[yy])     \n",
    "    return line,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=1\n",
    "na=200\n",
    "x_image=np.linspace(-a,a,na)\n",
    "y_image=np.linspace(-a,a,na).reshape(-1, 1)\n",
    "fig=plt.figure(figsize=(7,7))\n",
    "ax=plt.subplot(111)\n",
    "im = ax.imshow(f(x_image,y_image),cmap='viridis',animated=True)\n",
    "line=ax.plot([50], [50], 'ro',markersize=13,animated=True)[0]\n",
    "i=-1\n",
    "ani = an.FuncAnimation(fig, updatefig, interval=300, blit=True, frames=90)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clearly see that first red ball, which represents current state randomly wanders around, but as temperature lowers it starts to spend more time near center or, at least dark blue zone. Thus, simulated annealing has broad application in solving optimization problems and its major advantage is the ability to find global minimum. However, it is quite hard to get result with desired accuracy and sometimes a lot of the same experiments had to be done just to choose the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download file opt_lib.py and write there function sim_ann(energy,neighbour,hyperp,s0) where energy - energy function, neighbour - function which creates neighbour state of current state, hyperp - list of form [p0,pn,n], where p0 - initial probability, pn - final probability, n - number of iterations and s0 - initial state (a list of parametres). This function has to return s - optimal state after n iterations. <br>\n",
    "**Hint:** Yes! Functions can be inputs too! Take a look at this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def print_function(f,x):\n",
    "    print('f({0})={1}'.format(x,f(x))) #similar format of a string as in C#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_function(f,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We can change function and it will work!\n",
    "#The only restriction is that function f(x) has to have 1 argument\n",
    "def f(x):\n",
    "    return 2\n",
    "\n",
    "print_function(f,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use created module to optimize function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(a,b):\n",
    "    return (1*a+b-4)**2+(2*a+b-5)**2+(3*a+b-7)**2+(4*a+b-8)**2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
